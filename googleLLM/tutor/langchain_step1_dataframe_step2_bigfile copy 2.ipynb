{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6644e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tabulate==0.9.0\n",
    "# pip install langchain_experimental==0.3.4\n",
    "# pip install langchain==0.3.27\n",
    "# pip install langchain-google-genai==2.1.10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8e620",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/tools/pandas.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dfed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd215650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY is set.\n",
      "Value: AIzaSyAXq7IKW6QToj9MOeTA3uvADiAL3t8vv3c\n"
     ]
    }
   ],
   "source": [
    "# Check if GOOGLE_API_KEY is set in environment variables\n",
    "if \"GOOGLE_API_KEY\" in os.environ:\n",
    "    print(\"GOOGLE_API_KEY is set.\")\n",
    "    print(\"Value:\", os.environ[\"GOOGLE_API_KEY\"])\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d83e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ride_booking = pd.read_csv(\n",
    "    # \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"\n",
    "    \"/Users/najongseong/dataset/ncr_ride_bookings.csv\"\n",
    ")\n",
    "df_tatanic = pd.read_csv(\n",
    "    \"/Users/najongseong/dataset/titanic.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed888840",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm, df_ride_booking, verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b02db08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
      "Action Input: df.shape\u001b[0m\u001b[36;1m\u001b[1;3m(150000, 21)\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 150000\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how many rows are there?', 'output': '150000'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9cea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
      "Action Input: print(df.columns)\u001b[0m\u001b[36;1m\u001b[1;3mIndex(['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID',\n",
      "       'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT',\n",
      "       'Avg CTAT', 'Cancelled Rides by Customer',\n",
      "       'Reason for cancelling by Customer', 'Cancelled Rides by Driver',\n",
      "       'Driver Cancellation Reason', 'Incomplete Rides',\n",
      "       'Incomplete Rides Reason', 'Booking Value', 'Ride Distance',\n",
      "       'Driver Ratings', 'Customer Rating', 'Payment Method'],\n",
      "      dtype='object')\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: ['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'show me the column list',\n",
       " 'output': \"['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"show me the column list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d2bae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
      "Action Input: print(df['Vehicle Type'].value_counts().to_markdown())\u001b[0m\u001b[36;1m\u001b[1;3m| Vehicle Type   |   count |\n",
      "|:---------------|--------:|\n",
      "| Auto           |   37419 |\n",
      "| Go Mini        |   29806 |\n",
      "| Go Sedan       |   27141 |\n",
      "| Bike           |   22517 |\n",
      "| Premier Sedan  |   18111 |\n",
      "| eBike          |   10557 |\n",
      "| Uber XL        |    4449 |\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: | Vehicle Type   |   count |\n",
      "|:---------------|--------:|\n",
      "| Auto           |   37419 |\n",
      "| Go Mini        |   29806 |\n",
      "| Go Sedan       |   27141 |\n",
      "| Bike           |   22517 |\n",
      "| Premier Sedan  |   18111 |\n",
      "| eBike          |   10557 |\n",
      "| Uber XL        |    4449 |\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'vehicletype를 테이블로',\n",
       " 'output': '| Vehicle Type   |   count |\\n|:---------------|--------:|\\n| Auto           |   37419 |\\n| Go Mini        |   29806 |\\n| Go Sedan       |   27141 |\\n| Bike           |   22517 |\\n| Premier Sedan  |   18111 |\\n| eBike          |   10557 |\\n| Uber XL        |    4449 |'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"input\": \"vehicletype를 테이블로\"},\n",
    "             handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab0bc0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41aa4153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 shape: (891, 12)\n",
      "df2 shape: (150000, 21)\n",
      "\n",
      "df1 columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "df2 columns: ['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\n",
      "\n",
      "df1 info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "df2 info:\n",
      "df1 info:\n",
      "--- df1 (Titanic) ---\n",
      "Shape: (891, 12)\n",
      "Columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "--- df2 (Ride-sharing) ---\n",
      "Shape: (150000, 21)\n",
      "Columns: ['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\n",
      "Info:\n",
      "--- df1 (Titanic) ---\n",
      "Shape: (891, 12)\n",
      "Columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "--- df2 (Ride-sharing) ---\n",
      "Shape: (150000, 21)\n",
      "Columns: ['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating', 'Payment Method']\n",
      "Info:\n",
      "--- df1 (Titanic Data) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "--- df2 (Ride-sharing Data) ---\n",
      "--- df1 (Titanic Data) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "--- df2 (Ride-sharing Data) ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Here's a comparison of the two dataframes, highlighting their differences:\n\n**df1 (Titanic Dataset)**\n\n*   **Shape:** 891 rows, 12 columns.\n*   **Columns:** `PassengerId`, `Survived`, `Pclass`, `Name`, `Sex`, `Age`, `SibSp`, `Parch`, `Ticket`, `Fare`, `Cabin`, `Embarked`.\n*   **Data Types:** Primarily `int64` (for IDs, counts, classes), `float64` (for Age, Fare), and `object` (for Name, Sex, Ticket, Cabin, Embarked).\n*   **Missing Values:** Contains missing values in `Age`, `Cabin`, and `Embarked` columns.\n*   **Context:** Contains historical data about passengers on the Titanic, including personal details, ticket information, and survival status.\n\n**df2 (Ride-sharing Dataset)**\n\n*   **Shape:** 150,000 rows, 21 columns.\n*   **Columns:** `Date`, `Time`, `Booking ID`, `Booking Status`, `Customer ID`, `Vehicle Type`, `Pickup Location`, `Drop Location`, `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, `Payment Method`.\n*   **Data Types:** Primarily `object` (for Date, Time, IDs, Status, Locations, Reasons, Payment Method) and `float64` (for Avg VTAT, Avg CTAT, Cancelled Rides counts, Booking Value, Ride Distance, Ratings).\n*   **Missing Values:** Contains significant missing values across many columns, including `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, and `Payment Method`.\n*   **Context:** Contains operational data from a ride-sharing service, including booking details, ride metrics, cancellation reasons, and ratings.\n\n**Summary of Differences:**\n\n1.  **Size:** `df2` is much larger than `df1` in both the number of rows (150,000 vs 891) and columns (21 vs 12).\n2.  **Content/Domain:** `df1` is about individual passengers and their fate on the Titanic, while `df2` is about ride-sharing transactions and service performance.\n3.  **Column Names:** The column names are entirely different, reflecting their distinct domains. There are no common columns between the two dataframes.\n4.  **Data Granularity:** `df1` focuses on static passenger attributes and a single event (survival). `df2` focuses on dynamic ride events, metrics, and statuses.\n5.  **Missing Data Pattern:** While both have missing data, `df2` exhibits a more widespread pattern of missing values across a larger number of columns, particularly in performance and cancellation-related metrics.\n\nThe two dataframes are completely unrelated in terms of their subject matter and structure.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:455\u001b[39m, in \u001b[36mRunnableAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_runnable:\n\u001b[32m    449\u001b[39m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[32m    450\u001b[39m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3473\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3466\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3468\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3471\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3472\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3473\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3459\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3452\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3454\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3457\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3458\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3459\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3460\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3461\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3462\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3463\u001b[39m         **kwargs,\n\u001b[32m   3464\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2233\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2232\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2233\u001b[39m     chunk: Output = context.run(\u001b[38;5;28mnext\u001b[39m, iterator)\n\u001b[32m   2234\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3421\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3419\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3421\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1460\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1024\u001b[39m, in \u001b[36mRunnable.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Default implementation of ``stream``, which calls ``invoke``.\u001b[39;00m\n\u001b[32m   1012\u001b[39m \n\u001b[32m   1013\u001b[39m \u001b[33;03mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m \n\u001b[32m   1023\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    207\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    208\u001b[39m     config,\n\u001b[32m    209\u001b[39m     run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1953\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1950\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1951\u001b[39m         output = cast(\n\u001b[32m   1952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1955\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1956\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1957\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1958\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1959\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1961\u001b[39m         )\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:429\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:198\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    201\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    202\u001b[39m         config,\n\u001b[32m    203\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    207\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    208\u001b[39m     config,\n\u001b[32m    209\u001b[39m     run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    210\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain_core/output_parsers/base.py:251\u001b[39m, in \u001b[36mBaseOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[32m    238\u001b[39m \n\u001b[32m    239\u001b[39m \u001b[33;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    249\u001b[39m \u001b[33;03m    Structured output.\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/output_parsers/react_single_input.py:76\u001b[39m, in \u001b[36mReActSingleInputOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     75\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[32m     77\u001b[39m         msg,\n\u001b[32m     78\u001b[39m         observation=MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[32m     79\u001b[39m         llm_output=text,\n\u001b[32m     80\u001b[39m         send_to_llm=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     81\u001b[39m     )\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re.search(\n\u001b[32m     83\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*Action\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*Input\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*(.*)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m     text,\n\u001b[32m     85\u001b[39m     re.DOTALL,\n\u001b[32m     86\u001b[39m ):\n",
      "\u001b[31mOutputParserException\u001b[39m: Could not parse LLM output: `Here's a comparison of the two dataframes, highlighting their differences:\n\n**df1 (Titanic Dataset)**\n\n*   **Shape:** 891 rows, 12 columns.\n*   **Columns:** `PassengerId`, `Survived`, `Pclass`, `Name`, `Sex`, `Age`, `SibSp`, `Parch`, `Ticket`, `Fare`, `Cabin`, `Embarked`.\n*   **Data Types:** Primarily `int64` (for IDs, counts, classes), `float64` (for Age, Fare), and `object` (for Name, Sex, Ticket, Cabin, Embarked).\n*   **Missing Values:** Contains missing values in `Age`, `Cabin`, and `Embarked` columns.\n*   **Context:** Contains historical data about passengers on the Titanic, including personal details, ticket information, and survival status.\n\n**df2 (Ride-sharing Dataset)**\n\n*   **Shape:** 150,000 rows, 21 columns.\n*   **Columns:** `Date`, `Time`, `Booking ID`, `Booking Status`, `Customer ID`, `Vehicle Type`, `Pickup Location`, `Drop Location`, `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, `Payment Method`.\n*   **Data Types:** Primarily `object` (for Date, Time, IDs, Status, Locations, Reasons, Payment Method) and `float64` (for Avg VTAT, Avg CTAT, Cancelled Rides counts, Booking Value, Ride Distance, Ratings).\n*   **Missing Values:** Contains significant missing values across many columns, including `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, and `Payment Method`.\n*   **Context:** Contains operational data from a ride-sharing service, including booking details, ride metrics, cancellation reasons, and ratings.\n\n**Summary of Differences:**\n\n1.  **Size:** `df2` is much larger than `df1` in both the number of rows (150,000 vs 891) and columns (21 vs 12).\n2.  **Content/Domain:** `df1` is about individual passengers and their fate on the Titanic, while `df2` is about ride-sharing transactions and service performance.\n3.  **Column Names:** The column names are entirely different, reflecting their distinct domains. There are no common columns between the two dataframes.\n4.  **Data Granularity:** `df1` focuses on static passenger attributes and a single event (survival). `df2` focuses on dynamic ride events, metrics, and statuses.\n5.  **Missing Data Pattern:** While both have missing data, `df2` exhibits a more widespread pattern of missing values across a larger number of columns, particularly in performance and cancellation-related metrics.\n\nThe two dataframes are completely unrelated in terms of their subject matter and structure.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# agent = create_pandas_dataframe_agent(OpenAI(temperature=0), [df, df1], verbose=True)\u001b[39;00m\n\u001b[32m      2\u001b[39m agent = create_pandas_dataframe_agent(llm, [df_tatanic, df_ride_booking], verbose=\u001b[38;5;28;01mFalse\u001b[39;00m, allow_dangerous_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompare two dataframes and show me the difference\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repository/LLMProject/googleLLM/.venv/lib/python3.11/site-packages/langchain/agents/agent.py:1369\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[32m   1363\u001b[39m     msg = (\n\u001b[32m   1364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn output parsing error occurred. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1367\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1368\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1370\u001b[39m text = \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Here's a comparison of the two dataframes, highlighting their differences:\n\n**df1 (Titanic Dataset)**\n\n*   **Shape:** 891 rows, 12 columns.\n*   **Columns:** `PassengerId`, `Survived`, `Pclass`, `Name`, `Sex`, `Age`, `SibSp`, `Parch`, `Ticket`, `Fare`, `Cabin`, `Embarked`.\n*   **Data Types:** Primarily `int64` (for IDs, counts, classes), `float64` (for Age, Fare), and `object` (for Name, Sex, Ticket, Cabin, Embarked).\n*   **Missing Values:** Contains missing values in `Age`, `Cabin`, and `Embarked` columns.\n*   **Context:** Contains historical data about passengers on the Titanic, including personal details, ticket information, and survival status.\n\n**df2 (Ride-sharing Dataset)**\n\n*   **Shape:** 150,000 rows, 21 columns.\n*   **Columns:** `Date`, `Time`, `Booking ID`, `Booking Status`, `Customer ID`, `Vehicle Type`, `Pickup Location`, `Drop Location`, `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, `Payment Method`.\n*   **Data Types:** Primarily `object` (for Date, Time, IDs, Status, Locations, Reasons, Payment Method) and `float64` (for Avg VTAT, Avg CTAT, Cancelled Rides counts, Booking Value, Ride Distance, Ratings).\n*   **Missing Values:** Contains significant missing values across many columns, including `Avg VTAT`, `Avg CTAT`, `Cancelled Rides by Customer`, `Reason for cancelling by Customer`, `Cancelled Rides by Driver`, `Driver Cancellation Reason`, `Incomplete Rides`, `Incomplete Rides Reason`, `Booking Value`, `Ride Distance`, `Driver Ratings`, `Customer Rating`, and `Payment Method`.\n*   **Context:** Contains operational data from a ride-sharing service, including booking details, ride metrics, cancellation reasons, and ratings.\n\n**Summary of Differences:**\n\n1.  **Size:** `df2` is much larger than `df1` in both the number of rows (150,000 vs 891) and columns (21 vs 12).\n2.  **Content/Domain:** `df1` is about individual passengers and their fate on the Titanic, while `df2` is about ride-sharing transactions and service performance.\n3.  **Column Names:** The column names are entirely different, reflecting their distinct domains. There are no common columns between the two dataframes.\n4.  **Data Granularity:** `df1` focuses on static passenger attributes and a single event (survival). `df2` focuses on dynamic ride events, metrics, and statuses.\n5.  **Missing Data Pattern:** While both have missing data, `df2` exhibits a more widespread pattern of missing values across a larger number of columns, particularly in performance and cancellation-related metrics.\n\nThe two dataframes are completely unrelated in terms of their subject matter and structure.`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "# agent = create_pandas_dataframe_agent(OpenAI(temperature=0), [df, df1], verbose=True)\n",
    "agent = create_pandas_dataframe_agent(llm, [df_tatanic, df_ride_booking], verbose=False, allow_dangerous_code=True)\n",
    "agent.invoke(\"compare two dataframes and show me the difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c66dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
